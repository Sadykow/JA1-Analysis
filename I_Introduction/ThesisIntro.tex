Following Literature Review, this chapter will analyse the selected branch of Neural Networks in detail.
It explores the Recurrent NN in-depth and establishes the methodology for further research and implementation
The accuracy against complexity plot, Figure~\ref{fig:alg-comparioson}, states that there are two types of RNN worth detailed exploration and implementation: Long Short-Term Memory (LSTM) and Gradient Recurrent Unit (GRU).
Each type will be the subject of a detailed review with multiple published papers analysed, implemented and compared with percentage accuracy. 
%
%
Machine learning methods can establish relationships in complicated, multi-dimensional non-linear systems~\cite{hansen_support_2005,anton_battery_2013,he_state_2014}.
Many attempts to implement different NN exist, but the most promising were explored by following papers using Recurrent Neural Networks~\cite{song_lithium-ion_2018,Chemali2017,mamo_long_2020,jiao_gru-rnn_2020,xiao_accurate_2019,javid_adaptive_2020,zhang_deep_2020}.
RNN effectiveness in time-series dependant problems was shown using internal neurons to process data sequences with varying lengths~\cite{Chemali2017}.
The cells act as memory units, building relationships and giving output based on multiple inputs over time.

%
%
Over the past years, the RNN approach has received extensive attention from different researchers. The most recent attempt to determine the Li-Ion battery's remaining useful life was the Gradient Recurrent Unit models~\cite{song_lithium-ion_2018,javid_adaptive_2020,xiao_accurate_2019,jiao_gru-rnn_2020}.
The earliest approach utilised a battery charge's regression nature only using stateless models~\cite{song_lithium-ion_2018,jiao_gru-rnn_2020,xiao_accurate_2019} when input impact is not preserved for further predictions.
Later, some approaches introduced additional parameters to support the NN learning process~\cite{mamo_long_2020,jiao_gru-rnn_2020,javid_adaptive_2020}.
Besides good converges, the model's use was in determining critical events, like the time before complete charge depletion or overcharge.
However, it did not receive wide application due to the battery's initial state's requirement and prior utilisation as input features.
The most popular way lies in determining the charge's value using a fixed size history of voltage, current and temperature in stateless Long Short-Term Memory (LSTM) models~\cite{Chemali2017,mamo_long_2020,javid_adaptive_2020,zhang_deep_2020}.
The method's advantage is independent of the charge or discharge cycles at different times, as long as the history samples are in order.
However, estimation determines values based on fixed history samples and does not preserve for the next prediction, making practical estimation of single or several charge values, but not determining critical events ahead.
That can be achieved with stateful models, which continuously preserve the prediction's impact and can be propagated further until they reach the end state.

%
%
Both stateful and stateless methods fall for input samples' impact and their length.
Chemali et al.~\cite{Chemali2017} researched the impact of the history length of input samples: the longer the period of input readings, the better accuracy model produced and longer it takes to compute.
The result of the research is the root square parabola behaviour of size of the history against error in the prediction.
It was concluded that the length of five minutes made the most optimal trade-off between computational weight and general accuracy.
In addition, the normalisation technique is commonly used as a means to speed up the fitting process.
In the SoC estimation, scaling temperatures closer to the voltage and current reduce the time before the first valid results.
After identifying the most optimal input preferences without significant effect on the performance, one of the further developments apply changes to the structure of GRU or LSTM by adding additional layers (Attention or Extra Dense layers)~\cite{mamo_long_2020, jiao_gru-rnn_2020}.
Another way is to change the optimisation process to achieve similar accuracy faster (i. e., adding a Momentum algorithm to the Stochastic Gradient Optimisations process or replacing gradient calculations with statistical)~\cite{xiao_accurate_2019, javid_adaptive_2020}.
Those methods modify standard ways introduced earlier in model training by applying additional operations.
As a result, they met to achieve better accuracy faster using similar training approaches. 

%
%
The drawback lies within the validation procedures of produced models.
Ideally, this process must be performed with similar data but under different conditions or at different times.
However, once the produced model is taken through different unseen scenarios, the accuracy lowers drastically compared to early reported results since it starts to experience something completely unexpected.
The lack of training samples or means to produce at different conditions affected the final judgment results of many publications. 
Even though the estimation produces accurate output with tabled data, placed under actual driving conditions - the model will have difficulties matching training performance. 

%
%
Several attempts to introduce an online procedure for models performance measurement have been integrated into the training process to solve this problem.
By not being limited to the battery testing machine's table data, i.e. the validation mechanism to tune an NN model based on batteries data during actual battery cycling, researchers attempted to generalise the fitting process as best as hardware allowed~\cite{zhang_deep_2020}.
This method brings the model learning process closer to real-time battery utilisation without adding modelling complexity.

%
%
Table~\ref{tab:review} summarises the most common methods applied to SoC estimation, highlighting the model cell type, structure to define input sample type, optimiser selection, and additional features introduced by authors to improve predictions.
The model type highlights a primary path in structuring a Neural Net model.
The statefulness defines the input method, where stateless uses a fixed size of input samples per each feature and statefully apply each time sample at a time for all features one by one.
Optimiser selection sets the algorithm for the learning process from one of the following methods: Adaptive moment estimation (Adam), Nesterov adaptive moment estimation  (Nadam), Stochastic gradient descent (SGD), AdaMax (AM) and Differential Evolution (DE).
\begin{center}
    \begin{table}[h]
    \caption{Reviewed ML implementations for SoC estimation.}
    \label{tab:review}
\begin{tabular}{p{2.0cm}|p{0.8cm}|p{1.0cm}|p{0.8cm}|p{0.8cm}|p{1.0cm}|p{1.0cm}|p{0.9cm}|p{0.7cm}|p{0.7cm}|p{2.1cm}}
    %\multicolumn{12}{c}{Unknown yet table} \\
    \hline
    \multicolumn{1}{ c }{} & 
    \multicolumn{2}{|c|}{Model} & 
    \multicolumn{2}{ c|}{State-} & 
    \multicolumn{5}{ c|}{Optimiser} &
    \multirow{2}{ 4em }{Extension} \\
    \cline{1-4} \cline{5-10}
    Ref & GRU  & LSTM & -less & -ful & Adam & Nadam & SGD & AM & DE &           \\
    \hline
    Song~\cite{song_lithium-ion_2018}
        & \chk &      &       & \chk  & \chk &       &     &    &    & 4 Layers  \\
    Chemali~\cite{Chemali2017}
        &      & \chk & \chk  &       & \chk &       &     &    &    &           \\
    Mamo~\cite{mamo_long_2020}
        &      & \chk &  \chk &       &      &       &     &    &\chk& Attention \\
    Jiao~\cite{jiao_gru-rnn_2020}
        & \chk &      &       & \chk  &      &       & \chk&    &    & Momentum  \\
    Xiao~\cite{xiao_accurate_2019}
        & \chk &      &       & \chk  &      & \chk  &     &\chk&    & Ensemble  \\
    Javid~\cite{javid_adaptive_2020}
        & \chk &      & \chk  &       & \chk &       &     &     &   & Robust    \\
    Zhang~\cite{zhang_deep_2020}
        &      & \chk & \chk  &       &      & \chk  &     &     &   & Online    \\
    \hline
\end{tabular}
    \end{table}
\end{center}

%
%
All authors conducted model experiments on battery cycling data of different cell types.
The majority used table data of real-time sensory results from battery cyclers to validate efficiencies.
Data gets generated using different current schedulers, also referred to as driving profiles.
An equally time-based sample of current consumption acts as an input to the battery cycler, intended to recreate a stress test on a battery or human driving behaviour.
There are three the most commonly used in the research of this area: Dynamic Stress Test (DST), Aggressive Driving (US06) and Federal-Urban Driving Scheduler (FUDS).
Unlike some general simple static discharge processes, which commonly appear in other battery-based tools, driving profiles include some amount of regenerative driving to simulate the actual application of the battery for an electric vehicle.

%
%
Mamo et al.~\cite{mamo_long_2020} conducted experiments by validating the RNN model performance by training one driving profile and testing against another.
The results showed an increase in Root Mean Squared Error, comparing to single dataset training and validation scenario.
There have not been many similar experiments against other neural nets or other SoC estimation methods.
Usage of a single profile's battery cycling data may not validate ML methods' efficiency in driving an electric vehicle.
The inability to determine the charge's current state during EV driving makes the online learning process inapplicable.
Even with other SoC estimation technique usage, the computational complexity of training any NN is complicated to fit on a low power device.
An offline trained model had the advantage of insignificant resource consumption during the prediction stage, making it a prefered way for an EV.
All further model testing will be applied through varying battery cycling profiles to capture the influence of data type to model efficiency.

%
%
This chapter investigates, implements and compares extended memory-based models of RNN to predict the State of Charge and additional built-on over time techniques to select the most effective and least resource requiring onboard-based computations appliable within Electrical Vehicles.
The recent advances and commonly used subsets are Gradient Recurrent Unit and Long Shot-Term Memory unit cells.
Recurrent Neural Network has been confirmed to be suitable for the battery-related system by authors, such as Chemali ~\cite{LSTM_Hochreiter1997}.
However, there is no valid proof of if GRU or LSTM is helpful for battery SoC estimation.
The best way to separate them and explore differences and efficiencies is to use them as stateful and stateless models.
Each subset will contain implementation from various articles changing either structure of the models or learning approaches.
In the end, each method will be taken through the same battery data of DST, US06 and FUDS driving profiles and compared against robustness and accuracy of estimation State of Charge of Lithium-Ion batteries.

%
%
% The remaining sections are organised as follows: all methodology, methods and data discussed in Section~\ref{sec:Body}.
% The details of data management and models structure are in Subsection~\ref{subsec:RNN}.
% Subsections~\ref{subsec:structure},~\ref{subsec:optimisers} and~\ref{subsec:soft} separate all details for each GRU and LSTM method using multiple optimising algorithms.
% Section~\ref{sec:conclussion} gives the results of implementation, performance, discussion and concludes the critical analysis.