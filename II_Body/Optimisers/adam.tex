\subsubsection{Adam and Robust Online Adam}
The most commonly and by default used in Time-series prediction is Adaptive Moment Estimation~\cite{kingma_adam_2017} (Adam) optimiser.
The algorithm below highlights the steps required to update model weights and bias as per the source.
On top of two constants $\beta$ used for momentum calculation, the algorithm uses $\epsilon$, which referred to as fuzz factor.

%
%
Javid et al.~\cite{javid_adaptive_2020} extended the default $Adam$ algorithm introducing a Robust Online version of Adam, Line 10-12.
Adding the direct influence of loss function to the gradient update adds an online calculation to regular $Adam$ correction.
Table~\ref{tab:adam-params} highlight method-specific parameter selection for the optimiser.
The framework library contained no inbuild implementation of the Robust optimiser.
Instead, it was implemented from the first principal and overwriting the model training procedure.
The code itself can be located in Appendix~\ref{}
\begin{algorithm}\captionsetup{labelfont={sc,bf}, labelsep=newline}
  \caption{Adaptive Moment Estimation (Adam) optimisation}
  \begin{algorithmic}[1]
    \STATE \textbf{Number of input samples} \\ $N\gets length(\textit{input data})$\\
    \STATE \textbf{Size of windows} \\ $S\gets length(V_{i..n})$\\
    \STATE Input: $x_n = [V_{i..n}, I_{i..n}, T_{i..n}] - $Shape: $X = (N, S, 3)$
    \STATE Output:$y_n = [SoC_{n}] - $Shape:$Y = (N, 1)$
    \STATE Define Loss function: $L$ \\
           Get hyperparameters: $\alpha, \beta_1, \beta_2, \epsilon$
    \WHILE{$W_t \text{ not converge}$}
    \STATE $t \gets t+1$
    \STATE $g_t \gets \nabla_W L_t (W_{t-1})$ \COMMENT{Obtain gradient}
    \STATE $m_t \gets \beta_1 m_{t-1}+(1-\beta_1) g_t $ \COMMENT{$1_{st}$ moment calculation}
    \STATE $\upsilon_t \gets \beta_2 \upsilon_{t-1}+ \left(1-\beta_2 \right)g^2_t $ \COMMENT{$2_{nd}$ moment calculation \label{alg:Adam-Line-2Moment}}
    \STATE $\hat{m_t} \gets \frac{m_t}{1-\beta^t_1}$ \COMMENT{Corrected $\hat{m_t}$}
    \STATE $\hat{\upsilon_t} \gets \frac{\upsilon_t}{1-\beta^t_2} $ \COMMENT{Corrected $\hat{\upsilon_t}$}
    \STATE $W_t \gets W_{t-1}- \alpha \frac{\hat{m_t}}{\sqrt{\hat{\upsilon_t}}+\epsilon} $ \COMMENT{Update parameters}
    \ENDWHILE
  \end{algorithmic}
  \label{alg:Adam}
\end{algorithm}
% \begin{tabular}{ l } 
%     \hline
%     Algorithm Adam optimisation  \\
%     \hline
%     %\ \ \textbf{Input:} Data sample with shape=\left(1,500,1,3\right)\\ 
%     %\ \ \textbf{Output:} Predicted SoC shape=\left(1,500,1\right)\\ 
%     \ \ \ 1: Define I/O and Params: $\alpha, \beta_1, \beta_2, \epsilon $ \\
%     \ \ \ 2: Define loss function $L$ \\
%     \ \ \ 3: \textbf{while} $\phi_t$ not converge \textbf{do}: \\
%     \ \ \ 4: \ \ $t \leftarrow t + 1$ \\
%     \ \ \ 5: \ \ $g_t \leftarrow \nabla_\phi L_t \left(\phi_{t-1} \right) $ \text{\ \ \ //Obtain Gradient}\\
%     \ \ \ 6: \ \ $m_t \leftarrow \beta_1 m_{t-1}+ \left(1-\beta_1 \right)g_t $ \text{//$1^{st}$moment }\\
%     \ \ \ 7: \ \ $\upsilon_t\ \leftarrow \beta_2 \upsilon_{t-1}+ \left(1-\beta_2 \right)g^2_t $ \text{//$2^{nd}$moment }\\
%     \ \ \ 8: \ \ $\hat{m_t}\ \ \leftarrow \frac{m_t}{1-\beta^t_1}$ \text{Correct \ \ }$\hat{m_t}$\\
%     \ \ \ 9: \ \ $\hat{\upsilon_t}\ \ \leftarrow \frac{\upsilon_t}{1-\beta^t_2} $ \text{Correct \ \ }$\hat{\upsilon_t}$ \\ \\ \\ \\
%     \ \  10: \ \ $\phi_t \leftarrow \phi_{t-1}- \alpha \frac{\hat{m_t}}{\sqrt{\hat{\upsilon_t}}+\epsilon} $ \\
%     \ \  11: \textbf{end while} \\
%     \hline
% \end{tabular}
\begin{algorithm}\captionsetup{labelfont={sc,bf}, labelsep=newline}
  \caption{Robust Online Adaptive Moment Estimation (Adam) optimisation}
  \begin{algorithmic}[1]
    \STATE \textbf{Number of input samples} \\ $N\gets length(\textit{input data})$\\
    \STATE \textbf{Size of windows} \\ $S\gets length(V_{i..n})$\\
    \STATE Input: $x_n = [V_{i..n}, I_{i..n}, T_{i..n}] - $Shape: $X = (N, S, 3)$
    \STATE Output:$y_n = [SoC_{n}] - $Shape:$Y = (N, 1)$
    \STATE Define Loss function: $L$ \\
           Get hyperparameters: $\alpha, \beta_1, \beta_2, \beta_3, \epsilon$
    \WHILE{$W_t \text{ not converge}$}
    \STATE $t \gets t+1$
    \STATE $g_t \gets \nabla_\phi L_t (W_{t-1})$ \COMMENT{Obtain gradient}
    \STATE $m_t \gets \beta_1 m_{t-1}+(1-\beta_1) g_t $ \COMMENT{$1_{st}$ moment calculation}
    \STATE $\upsilon_t \gets \beta_2 \upsilon_{t-1}+ \left(1-\beta_2 \right)g^2_t $ \COMMENT{$2_{nd}$ moment calculation}
    \STATE $\hat{m_t} \gets \frac{m_t}{1-\beta^t_1}$ \COMMENT{Corrected $\hat{m_t}$}
    \STATE $\hat{\upsilon_t} \gets \frac{\upsilon_t}{1-\beta^t_2} $ \COMMENT{Corrected $\hat{\upsilon_t}$}
    \STATE $r_t \gets \parallel L_t\left(W_{t-1}\right)/L_t\left(W_{t-2}\right) \parallel $ \COMMENT{Relative prediction error term of the loss function}
    \STATE $d_t \gets \beta_3 d_{t-1}+\left(1-\beta_3\right)r_t $ \COMMENT{$3^{rd}$ moment calculation}
    \STATE $W_t \gets W_{t-1}- \alpha \frac{\hat{m_t}}{d_t\sqrt{\hat{\upsilon_t}}+\epsilon} $ \COMMENT{Update parameters}
    \ENDWHILE
  \end{algorithmic}
  \label{alg:RoAdam}
\end{algorithm}
% \begin{tabular}{ l } 
%     \hline
%     Algorithm Robust Adam optimisation  \\
%     \hline
%     %\ \ \textbf{Input:} Data sample with shape=\left(1,500,1,3\right)\\ 
%     %\ \ \textbf{Output:} Predicted SoC shape=\left(1,500,1\right)\\ 
%     \ \ \ 1: Define I/O and Params: $\alpha, \beta_1, \beta_2, \beta_3, \epsilon $ \\
%     \ \ \ 2: Define loss function $L$ \\
%     \ \ \ 3: \textbf{while} $\phi_t$ not converge \textbf{do}: \\
%     \ \ \ 4: \ \ $t \leftarrow t + 1$ \\
%     \ \ \ 5: \ \ $g_t \leftarrow \nabla_\phi L_t\left(\phi_{t-1}\right) $ \\
%     \ \ \ 6: \ \ $m_t \leftarrow \beta_1 m_{t-1}+\left(1-\beta_1\right)g_t $ \\
%     \ \ \ 7: \ \ $\upsilon_t\ \leftarrow \beta_2 \upsilon_{t-1}+\left(1-\beta_2\right)g^2_t $ \\
%     \ \ \ 8: \ \ $\hat{m_t}\ \ \leftarrow \frac{m_t}{1-\beta^t_1}$ \\
%     \ \ \ 9: \ \ $\hat{\upsilon_t}\ \ \leftarrow \frac{\upsilon_t}{1-\beta^t_2} $ \\
%     \ \ \ // Relative prediction error term of the loss function: \\
%     \ \ 10: \ \ $r_t \leftarrow \parallel L_t\left(\phi_{t-1}\right)/L_t\left(\phi_{t-2}\right) \parallel $ \\
%     \ \ 11: \ \ $d_t\ \leftarrow \beta_3 d_{t-1}+\left(1-\beta_3\right)r_t $ \text{//$3^{rd}$moment }\\
%     \ \ 12: \ \ $\phi_t \leftarrow \phi_{t-1}- \alpha \frac{\hat{m_t}}{d_t\sqrt{\hat{\upsilon_t}}+\epsilon} $ \\
%     \ \ 13: \textbf{end while} \\
%     \hline
% \end{tabular}
\begin{table}[htbp]
    \centering
    \caption{Adam, specific parameters}
    \label{tab:adam-params}
    \begin{tabular}{ p{6.0cm} p{1.5cm} p{1.5cm} p{1.5cm} p{1.5cm} p{1.5cm}  }
        \hline
        Source     & $\alpha$ & $\beta_1 $ & $\beta_2$ & $\beta_3$ &  $\epsilon$ \\
        \hline
        Song et al.~\cite{song_lithium-ion_2018} \& Chemale et al.~\cite{Chemali2017}
                & $0.001$ & $0.9$ & $0.999$ & |   &$10^{-8}$ \\% 0.0000001
        Javid et al.~\cite{javid_adaptive_2020}
                & $0.001$ & $0.9$ & $0.999$ & $0.999$ &$10^{-8}$ \\% 0.0000001
        %\hline
        \hline
    \end{tabular}
\end{table}


