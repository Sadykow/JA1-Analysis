\subsection{Model training, validation and testing metrics functions}
Following training procedure will be connducted similar to evaluation by Mamo \textit{et al.}~\cite{mamo_long_2020}.
Each model will undertake the same training, validation and testing procedure to evaluate the best technique and performance.
Training and validation over each iteration/epoch will be performed on a single driving profile but two different cells.
It intended not to correlate training and validation data samples.
The testing stage was performed on two cycles of the other driving profile to validate overall capture.

%
%
Every model will be fitted on the training set of input windows for a single selected driving profile.
After each set, a validation on the similar but another cell at ambient 25\textdegree{}C temperature will be performed to get initial model performance.
The validation set is created from unseen data to report the accuracy and asses general behavior capture of the training process only.
The training itself will be performed until the predefined loss function gets the error below 2,4\% or achieve maximum possible accuracy until overfit happens.
The learning steps will not be affected by the overfitting process, and each failure will be preloaded with a previous successfully trained model and repeated training several times.
%
Testing performance against two cycles of each unsued driving profile using one of the available embedded devices capable of Machine Learning.
The intention was to verify that models will be capable of being used at low power devices and still meet necessary performance requirements.
%
So-called cross-validation mechanism, the profile will be switched to another and perform precisely the same training, validation and testing steps.
Each result is summarised into a table and reported based on metrics values.
%
Based on the progressive error degradation, a final iteration for the discussion will be based on the lowest training and validation error.
After, the successful model will be taken through the entire unseen dataset to calculate overall accuracy against two remaining profiles.
% Following plot demonstrates how multi-processing unit testing process is performed for all 3 driving profiles over single model. 

%
Test procedure performed on two cycles of each profile but at a different temperature to assess how perceptive model is to capture average and high temperature at which accumulator may end up.

%
%
% \subsubsection{Losses}~\label{subsub:losses}
\begin{figure}[ht]
    % RMSE equation: RMS = (tf.keras.backend.sqrt(tf.keras.backend.square(y_test_one[::,]-PRED)))
    \centering
    \includesvg[width=\columnwidth]{II_Body/images/plot-example.svg}
    \caption{Accuracy plot demonstration.}
    \label{fig:plot_demo}
\end{figure}
\begin{equation}
    \textbf{RMS error}  = \sqrt{(Actual-Prediction)^2}
    \label{eq:rms-error}
\end{equation}
\textbf{For better visualsation, standard RMS equation has been replaced with following. No division by 2. Scaled for better visualisation. Squared used to absolute difference}
\mbox{Table~\ref{tab:experiment}} contains a separate column for every loss functions, which has been applied to each tested model.
Some equations were extracted directly from papers; others were written based on their definition and internal library implementation.
The goal of the loss function is to calculate the error between model prediction and the actual value.
The efficiencies and impact of each equation are hard to determine and are not the investigation's goal.
The purpose of the table is only to provide the implementation references, which has been assumed during the programming of each published article based model.
% \begin{table*}[htbp]
%     \renewcommand{\arraystretch}{1.3}
%     \caption{Model's loss functions}
%     \centering
%     \label{tab:losses}
%     \resizebox{\linewidth}{!}{
%     \begin{tabular}{ l l l c }
%         \hline\hline \\[-3mm]
%         Function Name & Method used in & Source articles & Equation \\ 
%         \hline
%         Absolute Error & & Song \textit{et al.}~\cite{song_lithium-ion_2018} & $|SoC_t-\hat{SoC_t}|$ \\
%         \hline
%         -- &\#1 \#4 & \makecell[l]{Chemal \textit{et al.}\cite{Chemali2017},\\Jiao \textit{et al.}~\cite{jiao_gru-rnn_2020}} & $\sum\limits^N_{t=0} \frac{1}{2} (SoC_t-\hat{SoC_t})^2$ \\
%         \hline
%         \makecell[l]{Mean Average\\ Percentage Error} &\#3 & Mamo \textit{et al.}~\cite{mamo_long_2020} & $\frac{100}{N}\sum\limits^N_{t=0}|\frac{SoC_t-\hat{SoC_t}}{SoC_t}|$ \\
%         \hline
%         -- &\#2 & Xiao \textit{et al.}~\cite{xiao_accurate_2019} & $\frac{\sum\limits^N_{t=1}(SoC_t-\hat{SoC_t})^2}{N}$ \\
%         \hline
%         \makecell[l]{Mean Average\\ Squared Error} &\#5 \#6 & \makecell[l]{Javid \textit{et al.}~\cite{javid_adaptive_2020},\\Zhang \textit{et al.}~\cite{zhang_deep_2020}} & $\sum\limits^N_{t=0} \sqrt{\frac{1}{n} (SoC_t-\hat{SoC_t})^2}$ \\
%         \hline\hline
%     \end{tabular}
%     }
% \end{table*}

% $ L = \sum\limits^N_{t=0} \frac{1}{2} (SoC_t-\hat{SoC_t})^2$ ~\cite{Chemali2017},~\cite{jiao_gru-rnn_2020} \\
% $ L = \sum\limits^N_{t=0} \sqrt{\frac{1}{n} (SoC_t-\hat{SoC_t})^2}$ ~\cite{javid_adaptive_2020}~\cite{zhang_deep_2020} \\
% $ L = (\sum\limits^N_{t=1}(SoC_t-\hat{SoC_t})^2)N$~\cite{xiao_accurate_2019} \\
% $ L = |SoC_t-\hat{SoC_t}|$ \\
% $ L = \frac{100}{N}\sum\limits^N_{t=0}|\frac{SoC_t-\hat{SoC_t}}{SoC_t}|$~\cite{mamo_long_2020} \\

% \ebd{table}
% $MAE = \frac{1}{N}\sum\limits^N_{t=1} |SoC_t-\hat{SoC_t}|$ \\
% $MAPE = \frac{100}{N}\sum\limits^N_{t=1}|\frac{SoC_t-\hat{SoC_t}}{SoC_t}|$ \\
% $RMSE = \sqrt{\frac{1}{N}\sum\limits^N_{t=1}(SoC_t-\hat{SoC_t})^2}$ \\
% $R^2 = 1-\frac{\sum\limits^N_{t=1}(SoC_t-\hat{SoC_t})^2}
%               {\sum\limits^N_{t=1}(SoC_t-M_{SoC})^2}$ - $M_{SoC}$ is the mean SoC \\
% $Error = \frac{SoC_t-\hat{SoC_5}}{SoC_t}$ - Not decided yet
% \subsubsection{Callbacks}
% For stateless model, the method for reseting a State of model has been derived with Callback function of:
% Another Algorithm. \\
% \begin{lstlisting}[language=Python]
% class ResetCallback(tf.keras.callbacks.Callback):
%     reset_steps : int = 500
%     i_counter   : int = 0
%     def __init__(self):
%         self.i_counter = 0

%     def on_batch_begin(self, batch, logs=None):
%         if (self.i_counter % self.reset_steps) == 0:
%             self.model.reset_states()
%             self.i_counter = 0
%         self.i_counter += 1
% \end{lstlisting}
% \begin{enumerate}
%     \item Checkpoint saving only the best one based on smalest rmse
%     \item Tensorboard tmp folder
%     \item Early stopping is applyable
%     \item Procedure of training epoch by epoch or algorithm for offline and online.
% \end{enumerate}
% \subsubsection{Callbacks}
% \begin{itemize}
%     \item Checkpoint \\
%     \item Tensorboard \\
%     \item nanTerminate \\    
% \end{itemize}
% \subsubsection{Training and validation Loop??}
% \begin{itemize}
%     \item validation over what data? - single cycle \\
% \end{itemize}
% \subsubsection{Testing procedures??}
% \begin{itemize}
%     \item Converting model to the TF-Lite usage for TPU processor \\
%     \item 2 profiles - two cycle test \\
% \end{itemize}

%
%
% \subsubsection{Metrics}
% \textcolor{red}{Generally, Losses start form 0, metrics from 1. Articles which did overwise were assumed to be mistaken.}
% \textcolor{red}{Similar to loses and reasons why we have chosen those as out criterias.} \\
Metrics functions act as user evaluation criteria to assess the performance of the trained model during both fitting and validation processes.
Although some papers relied on different evaluation criteria, for this research, metrics were unified with several equations from \mbox{Table~\ref{tab:metrics}}.
Thus, the same criteria will be used for the final comparison between models' efficiency against each other.
\begin{table}[htbp]
    \renewcommand{\arraystretch}{1.3}
    \caption{Model's metrics functions}
    \centering
    \label{tab:metrics}
    \resizebox{\columnwidth}{!}{
    \begin{tabular}{l c}
        \hline\hline \\[-3mm]
        Function Name & Equation \\ 
        \hline
        \makecell[l]{Mean Absolute\\ Error} &  $\frac{1}{N}\sum\limits^N_{t=1} |SoC_t-\hat{SoC_t}|$ \\
        % \hline
        % Mean Average Percentage Error & $\frac{100}{N}\sum\limits^N_{t=1}|\frac{SoC_t-\hat{SoC_t}}{SoC_t}|$ \\
        \hline
        \makecell[l]{Root Mean\\ Square Error} & $ \sqrt{\frac{1}{N}\sum\limits^N_{t=1} \left(SoC_t-\hat{SoC_t} \right)^2}$ \\
        \hline
        \makecell[l]{$R^2$ : $M_{SoC}$ is\\ the mean SoC} & $1-\frac{\sum\limits^N_{t=1}(SoC_t-\hat{SoC_t})^2}
                {\sum\limits^N_{t=1}(SoC_t-M_{SoC})^2}$ \\
        \hline\hline
        % Error : Not decided if useful yet & $ \frac{SoC_t-\hat{SoC_5}}{SoC_t}$
    \end{tabular}
    }
\end{table}

