\subsection{Hyperparameters selection} \label{subsec:l-rate}
% Methods and their optimisers
%
The reviewed articles used constant hyperparameters values for models and optimisers, including learning rate.
However, each selected different values based on experiments and observations, somewhere in the range of 0.001, the standard framework provided, down to 0.0005(0.0001), to make a smooth stepping and minimise potential missing the optimum minimum.
A detailed overview of each method has been marked in \mbox{Table ~\ref{tab:experiment}}.

% Recovery from faults.
%
\begin{figure}[htbp]
  \centering
  \begin{subfigure}[b]{0.45\textwidth}
      \centering
      \includesvg[width=\linewidth]{II_Body/images/history-bad.svg}
      \caption{Model training process with no rollbacks}
      \label{subfig:no-rollback}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.45\textwidth}
      \centering
      \includesvg[width=\linewidth]{II_Body/images/history-good.svg}
      \caption{Model training process with a rollback if current error higher than previous.}
      \label{subfig:rollback}
  \end{subfigure}
  \caption{Training process comparison with and without having a recovery algorithm.}
  \label{fig:rollback}
\end{figure}
As a result, a separate learning rate scheduler has been used instead of applying each learning rate separately for every model.
Therefore, a stepping learning rate algorithm has been used for every optimiser over the training course.
However, continuous learning rate reduction does not resolve the issue of overfitting or missing a minimum.
The best approach to save time and produce reliable results was to enforce a model to carry on the selected course.
Since each model undergoes multiple attempts, there are good chances to explore multiple different fitting scenarios rather than jumping between them.
Two subfigures on \mbox{Figure~\ref{fig:rollback}} demonstrate two different training attempts with and without a recovery algorithm.
While subfigure~\ref{subfig:no-rollback} keeps the training process until either the number of 100 epochs gets reached or rapid overfit, the subfigure~\ref{subfig:no-rollback} continues reaching the selected minimal for as long as it can achieve a result.
Considering that all attempts to train the estimator eventually tended to overfit, the learning rate's value has been reduced by half each time model recovers from overshoot.
However, it did not affect the follow-up training, meaning that the learning rate always followed the stick degradation curve as per Figure~\ref{fig:l_rate_progress}.
Epochs 26 and further indicate the training attempt to recover from the overfitting state on an LSTM model, reducing the rate in several dozen attempts, never reaching zero.
Once the model fails to improve the accuracy, it is considered the most optimum fit to initiate early stopping.
\begin{figure}[ht]
    \centering
    \includesvg[width=\linewidth]{II_Body/images/l_rate.svg}
    \caption{Learning rate degradation.}
    \label{fig:l_rate_progress}
\end{figure}

% Betas and Epsilon instead on every optimiser page
%
The betas and epsilon did not go through any similar optimisation process due to a lack of documented training attempts to improve fitting over State of Charge estimation on Lithium-Ion batteries.
As a result, they were kept constant for all trained models, except SGD with Momentum as per \mbox{Table~\ref{tab:uni-hyperparams}}.
Since Stochastic Gradient Descent does not use any other hyper-parameters except learning rate and single beta constant, its' value was set to $\beta_1 = 0.8$
\begin{table}[htbp]
  \renewcommand{\arraystretch}{1.3}
  \caption{Optimisers Hyper-Parameters}
  \centering
  \label{tab:uni-hyperparams}
  \resizebox{\columnwidth}{!}{
  \begin{tabular}{ l l l l l l }
      \hline\hline \\[-3mm]
      $\alpha$ & $\beta_1 $ & $\beta_2$ & $\beta_3$ &  $\epsilon$ \\
      \hline
      Linear         &  &  &  & \\% 0.0000001
      Scheduler      & $0.9$ & $0.999$ & $0.999$ &$10^{-8}$ \\% 0.0000001
      (0.001-0.0005) &  &  &  & \\% 0.0000001
      \hline\hline
  \end{tabular}
  }
\end{table}

% Layers and neurons
%
All reviewed articles used a constant number of layers and neurons to conduct the experiments.
None have provided any reasoning for the selections or results from other attempted experiments without changing the technique.
The least time-consuming method evaluated the most promising combination of the number of layers and neurons to create the best similar circumstances for all methods.
The most promising candidates were taken through a dozen similar attempts to get an average result and produce several selection criteria for later use.
