\subsection{Hyperparameters selection} \label{subsec:l-rate}
% Methods and their optimisers
%
%! Five stated models
The reviewed articles from which the chosen models were selected for testing used constant hyperparameter values for models and optimisers, including learning rate.
However, each selected different values based on experiments and observations, somewhere in the range from 0.001 (the standard framework provided) down to 0.0001, to ensure a smooth stepping and minimise the potential of missing the optimum minimum.
% A detailed overview of each method has been marked in \mbox{Table ~\ref{tab:experiment}}.

% Recovery from faults.
%
% Put a pseudo code for scheduler degradation.
% elif type == 'linear':
%   return linspace(0.001, 0.0001, 100)[epoch]
%   step = (stop - start) / (num - 1)
% for i in range(num):
%   yield start + step * i
% \begin{algorithm}\captionsetup{labelfont={sc,bf}, labelsep=newline}
%   \caption{Linear Scheduler implementation. Equivalent of \textit{linspace()} fn}
%   \begin{algorithmic}[1]
%     \STATE \textbf{Starting value} \\ $start\gets \textit{initial Learning rate}$\\
%     \STATE \textbf{End Value} \\ $stop\gets \textit{final Learning rate}$\\
%     \STATE \textbf{Number of iterations/Epochs} \\ $N = \textit{Epochs}$\\
%     \STATE \textbf{Calculate step between starting and end values, \\ including final learning rate} \\ $step = (stop - start) / (N - 1)$\\
%     \WHILE{$epoch \leq N$}
%     \STATE $\alpha \gets start + step * epoch$ \\ \COMMENT{Yield learning rate to an optimiser}
%     \ENDWHILE
%   \end{algorithmic}
%   \label{alg:scheduler}
% \end{algorithm}
% alpha_1 = alpha + delta
% Define delta degradation of learning rate
% Delta wash chosen to go from init to end. Decrement.
\begin{equation}
  \begin{split}
    IF \ AN \ & OVERFIT: \\
      \hat{\alpha} &= \frac{\hat{\alpha} }{2} \\
    ELSE: & \\
      \Delta &= \frac{stop - start}{N-1} \\
      \hat{\alpha} &= \alpha - \Delta \times epoch
    \label{eq:scheduler}
  \end{split}
\end{equation}
% As a result, a separate learning rate scheduler has been used instead of applying each learning rate separately for every model.
In this work, a stepping learning rate algorithm was used for every optimiser over the training course given by Equation~(\ref{eq:scheduler}).
The implementation was equivalent to a \textit{linspace} function, where every epoch's learning rate $\hat{\alpha}$ was calculated through \textit{start} and \textit{stop} variables, indicating the boundaries of rate degradation, with a $\Delta$ decrement through a total of \textit{N} iterations and the known $\alpha$ value.
%
% Like adaptive time stepping in Finite Element Analysis [ref] by Pr David Holmes
The learning rate was sequentially reduced following a standard stepped scheme.
However, an additional adaptive phase was introduced in this work.
The training error was reduced in subsequent epochs when the stepped scheme was followed. %please check intended meaning has been retained %? Sadykov: Still confusing, but I guess the original was even worse. So be it.
The adaptive scheme was deployed if the learning error increased from one epoch to the next.
Then, the rate was halved, and the same epoch was rerun.
If the training error remained above the error of the previous epoch, the learning rate continued to be reduced to a predetermined minimum.
The prior stepped scheme resumed if the error returned to a convergent value.
Figure~\ref{fig:l_rate_progress} shows two adaptive schemes that were applied and reconverged, and a final ultimate adaptive decay ended the training.
%
Based on two training tests in Figure~\ref{fig:rollback}, with and without this approach, the rollback method was found to be superior to other adaptive learning rate schemes presented in this work and was employed for all subsequent training.
%
% However, continuous learning rate reduction does not resolve the issue of overfitting or missing a minimum.
% The best approach identified in this work to save time and produce reliable results has been to enforce a model to stick toward a single minimum.
% In this case, the learning rate always follows the stick degradation curve as per Figure~\ref{fig:l_rate_progress}, without affecting the follow-up training with steep rate reduction upon failures.
% Since each model undergoes multiple attempts, there are good chances to explore a variety of different fitting scenarios rather than jumping between several minimal.
% Two subfigures on \mbox{Figure~\ref{fig:rollback}} demonstrate two different training attempts with and without a recovery algorithm.
% While subfigure~\ref{subfig:no-rollback} keeps the training process until either the number of 100 epochs gets reached or rapid overfit, the subfigure~\ref{subfig:no-rollback} continues reaching the selected minimal for as long as it can achieve a result.
% Considering that all attempts to train the estimator eventually tended to overfit, the learning rate's value has been reduced by half each time model recovers from overshoot, Equation~\ref{eq:scheduler}.
% Epochs 26 and further indicate the training attempt to recover from the overfitting state on an LSTM model, reducing the rate in several dozen attempts, never reaching zero.
% Once the model fails to improve the accuracy, it is considered the most optimum fit to initiate early stopping.

\begin{figure}[ht]
  \centering
  \includesvg[width=\textwidth]{II_Body/images/l_rate.svg}
  \caption{Learning rate degradation}
  \label{fig:l_rate_progress}
\end{figure}
\vspace{-6pt}
\begin{figure}[H]
  % \centering
  \begin{subfigure}[b]{0.45\textwidth}
    % \centering
    \includesvg[width=6cm]{II_Body/images/history-bad.svg}
    \caption{\centering}
    \label{subfig:no-rollback}
  \end{subfigure}
  % \hfill
  \begin{subfigure}[b]{0.45\textwidth}
    % \centering
    \includesvg[width=6cm]{II_Body/images/history-good.svg}
    \caption{\centering}
    \label{subfig:rollback}
  \end{subfigure}
  \caption{Training process comparison with and without a recovery algorithm. (\textbf{a}) Model training process with no rollbacks; (\textbf{b}) model training process with a rollback if the current error is higher than the previous error.}
  \label{fig:rollback}
\end{figure}

% Betas and Epsilon instead on every optimiser page
%
The betas and epsilon optimiser constants did not go through any similar optimisation process, due to a lack of documented training attempts to improve fitting over the state-of-charge estimation on lithium-ion batteries.
As a result, they were kept constant for all trained models except SGDw/M.
Since the stochastic gradient descent does not use any hyperparameters except the learning rate and the single beta constant, its value was set to $\beta_1 = 0.8$.
The learning rate limits of the scheduler and remaining hyperparameters used in all cases are summarised in \mbox{Table~\ref{tab:uni-hyperparams}}.
\ifthenelse{\boolean{thesis}}{
\begin{table}[htbp]
  \renewcommand{\arraystretch}{1.3}
  \caption{Optimiser Hyper-Parameters}
  \centering
  \label{tab:uni-hyperparams}
  \begin{tabular}{ l l l l l l }
      \hline\hline \\[-3mm]
      $\alpha$ & $\beta_1 $ & $\beta_2$ & $\beta_3$ &  $\epsilon$ \\
      \hline
      Linear         &  &  &  & \\% 0.0000001
      Scheduler      & $0.9$ & $0.999$ & $0.999$ &$10^{-8}$ \\% 0.0000001
      (0.001-0.0001) &  &  &  & \\% 0.0000001
      \hline\hline
  \end{tabular}
\end{table}
} {
\begin{table}[H]
  \caption{Optimiser's Hyperparameters.}
  \label{tab:uni-hyperparams}
  \newcolumntype{C}{>{\centering\arraybackslash}X}
  \begin{tabularx}{\textwidth}{CCCCCC}
    \toprule
    \boldmath{$\alpha$} & \boldmath{$\beta_1 $} & \boldmath{$\beta_2$} & \boldmath{$\beta_3$} & \boldmath{$\epsilon$} \\
    \midrule
    Linear    & & & & \\
    scheduler   & $0.9$ & $0.999$ & $0.999$ &$10^{-8}$ \\
    (0.001--0.0001) & & & & \\
    \bottomrule
  \end{tabularx}
\end{table}
}
% Layers and neurons
%
The work performed by other authors, in Table~\ref{tab:review}, used a constant number of layers and neurons to conduct the experiments.
Only a few provided their reasoning for the selections or results obtained from other attempted experiments without changing the \linebreak technique~\cite{jiao_gru-rnn_2020,mamo_long_2020}.
The least time-consuming method evaluated the most promising combination of layers and neurons to create the best, similar circumstances for all methods.
The most promising candidates were taken through a dozen similar attempts to obtain an average result and produce several selection criteria for later use.
