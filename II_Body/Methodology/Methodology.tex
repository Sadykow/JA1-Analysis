% Introduction to the section with the usual ML process outline.
%
%The following section will describe the methodology of evaluation analysis of the reviewed methods, data sources and built pipelines, procedures for training, validation and testing, and final error calculation. \\
% Purpose of the article. Prototype existing models on low-power devices.
% \subsection{Types of ML model for evaluation}
The methodology evaluation section will attempt to prototype and deploy a Neural Network model from existing methods to identify the best candidate for integration into an electric vehicle's battery management system.
One of the objectives is to analyse several different RNN models, measure their performance, and determine the most promising direction for further enhancing the integration of a Neural Network model into an accumulator inside an EV.
% Roadmap
%
% \textbf{ROADMAP: Explain sections}
% \begin{itemize}
%     \item Data used for testing \\
%     \item Learning, testing, validation methods \\
%     \item Hyper-parameters: \\
%     \begin{itemize}
%         \item layers \\
%         \item neurons (depth) \\
%         \item learning rate 
%     \end{itemize}
% \end{itemize}
% \textcolor{blue}{
% Subsection~\ref{subsec:b_data} will cover the origin of the battery data, what they represent, its' type, properties, size and usability in the model preparation.
% Like any other model preparation, subsection~\ref{subsec:t_model} will cover the cross-validation process, involving data split between training, validation and testing datasets and data augmentation for an ML model to work.
% Subsection~\ref{subsec:l-rate} will cover the hyper-parameters, which models will share through the training process to achieve the optimum results.
% To make all researched models have equal opportunities to prove themselves, a set of parameters will first be investigated and reported as the best suited for battery management system purposes before diving into specific implementations.
% Finally, subsection~\ref{subsec:dataset} summarises and sets up the starting point shared across all models through the entire research process.
% }

%
% Must start with the general methodology
% \begin{itemize}
%     \item 6 models
%     \item Data used
%     \item Testing procedure
% \end{itemize}
% It is the objective if this papaer \\
% tested in this study were impl,emented as faithfully as possible to the original published versions.
% Unlike SoC which scaled to percentage view, Error was preserved in the initial form to avoid overlapping with charge plots.
% It is intended only to visualise the region affected by the error on a full y-axis scale from 0 to 100\%.

% \\\\\\
% %! Remove or reallocate that part beginning or second part or write new with DST, US06 and FUDS.
% Several attempts to introduce an online procedure for model performance measurement have been integrated into the training process to solve this problem.
% By not being limited to the battery testing machine's table data, i.e. the validation mechanism to tune an NN model based on battery data during actual battery cycling, researchers attempted to generalise the fitting process as best as hardware allowed~\cite{zhang_deep_2020}.
% This method brings the model learning process closer to real-time battery utilisation without adding modelling complexity.
% \subsection{Managing input data} \label{subsec:RNN}
% Although the perfect replication was impossible due to a lack of details and actual battery data used by different authors. All models were implemented based on the provided information.
%
%
%
% The structure and number of units define the number of layers of particular cell types with the total number of neurons evenly shared across layers.
% The statefulness parameter describes the model's ability to preserve its' current state for the next set of input parameters.
% Based on that, the input amount of samples becomes flexible by the requirement of adding only a single sample at a time upon their arrival, instead of waiting until the fixed amount has accumulated into a fixed-size time window.
% The optimiser selection was based on the derivative calculation algorithms only.
% Other alternatives, like differential evolution, are beyond the scope of research.
% Finally, "Extension" defines the model's specific detail, which distinguishes it against the others.
%
%
%
% Thus the specifics of each algorithmic aspect will be defined further~\ref{subsec:dataset},~\ref{subsec:structure}:
% \begin{enumerate}[1)]
%     \item Data shape for each state type
%     \item Model structure and the difference between GRU and LSTM
%     \item Each optimisation algorithm and hyper-parameters selection
% \end{enumerate}
