Since it is common for temperatures in the accumulator inside an EV to spike from ambient 20 degrees to the limit of 60, all temperature ranges were used together to train each model.
The training process was conducted through all datasets for a single battery testing profile and validated on a single cycle of unseen data of 25\textdegree{}C (less or around 20\% of the entire set).
This approach led to the accuracy being lower than other researchers reported by training individually for temp ranges like with Xiao et al.~\cite{xiao_accurate_2019}.
The following section compares the models trained on each individual and then tests against the entire dataset of all three profiles.
All examples were trained using charge and discharge cycles and an initially predetermined set of hyperparameters to make an objective comparison.

%
%
% Final tests for a model performance were conducted against an entire set of two remaining profiles separately.
The metrics were reported using the equations outlined in the \mbox{Table~\ref{tab:metrics}}.
Figures were generated during each iteration of the training process from the data samples outlined in the \mbox{Subsection~\ref{subsec:b_data}}.
After completing the predefined amount of epochs, each metric was recorded in a comma-separated file to produce accuracy plots, allowing assessment of the efficiency of the learning process.

% The Evaluation process of layers and neurons to get the best set
%
The hyperparameters selection process based on evaluating the best set of layers and neurons for all research models has been determined and recorded before the primary training process.
\mbox{Tables~\ref{tab:param-search1} and~\ref{tab:param-search2}} based on the average of three attempts per each current profile has been produced, sorted by applicable criteria and used through the rest of the experiments.
The lowest mean average error and relative memory size were selected as primary research aspects.
It is important to note that those parameters are not universally applicable to any other kind of battery or telemetries from electric vehicles.
The set of hyperparameters may have been a good one for applicable data in this research.
However, that evaluation would have to be repeated for other batteries or deployments with car endurance records.

%
%
\mbox{Two tables, \ref{tab:acc-results1} and \ref{tab:acc-results2}}, contains results of accuracy validation on six implemented models over entire drive cycles datasets.
\mbox{Figures between \ref{fig:Model-1res} and \ref{fig:Model-6res}} demonstrated the best-selected cases for visual demonstration and comparison of training on one profile and validation against the other two.
\mbox{Figures \ref{fig:Model-1losses} to \ref{fig:Model-6losses}} refer to the best model over the learning process, based on minimum Mean average or Root Mean Squared errors.

%
%
\subsection{Hyperparameters evaluation}
The ranges between 1 to 3 layers and incremental combinations of neurons from 131 to 1572 were used to determine the most optimum set of hyperparameters for all models to work with.
Any values higher or lower of both parameters did not provide worthy outputs, therefore, has been amended from the research.
In a case with multiple layers, the number of neurons gets evenly distributed per layer, narrowed to the lowest integer.
For example, three layers at 1048 neurons would represent each LSTM or GRU layer containing only 349.
%%%%%%%%%%%%%%%
Training simple LSTM models with Adam optimiser for three current profiles three times resulted in a total of 135 trained models.
They all can be summarised in 15 different sets of hyperparameters to compare.
\mbox{Tables~\ref{tab:param-search1} and~\ref{tab:param-search2}} report the average results of the five best models based on the lowest average training error and occupied memory space in a compressed state in ??? (MB).
The time in seconds highlights the duration of training over a single epoch.
For online training on a low-power device, it could be considered as an essential factor, sacrificing some amount of accuracy, but not in this research.
The angle of inclination is a line fit to the average error training over time, starting from the second epoch until the end of the training.
It can be determined either by visual examination of the average training curve of all attempts or through a simple line fitting, where negative or positive reversed tangent of angle alpha will represent converges or divergence and constant C the height of the curve or average error.
%
% It reports the trend of the model performance, where alpha represents the angle and c the hights.
% In the tables below, the negative \textbf{revesersed tangent?} represents the error degradation, there as the positive a clear overfit.
As a result, a model with index 10 with three layers and a total of 131 neurons (43 per layer) has been selected as the main researched hyperparameter for all follow-up models.
% \textbf{Angle of inclination of a line tanh-1(alpha) without adding 180 }
\begin{table}[htbp]
  \renewcommand{\arraystretch}{1.3}
  \caption{Hyper-params selection - Sorted by Average MAE}
  \centering
  \label{tab:param-search1}
  \resizebox{\columnwidth}{!}{
  \begin{tabular}{ l l r r r r}
      \hline\hline \\[-3mm]
      $ index $ & $L$x$N$ & $size $ & $time(s)$ & $	\angle $ inclination & \textbf{avr MAE}\\
      \hline
      10        & 3x131   & 0.17    & 2112.38   & converges            & \textbf{2.5137} \\
      11        & 3x262   & 0.63    & 2304.04   & converges            & \textbf{2.8515} \\
       6        & 2x262   & 0.85    & 1670.61   & converges            & \textbf{2.8789} \\
       5        & 2x131   & 0.22    & 1429.47   & converges            & \textbf{3.0303} \\
       7        & 2x524   & 3.33    & 1990.49   & diverges             & \textbf{3.0303} \\
      \hline\hline
  \end{tabular}
  }
\end{table}
\begin{table}[htbp]
  \renewcommand{\arraystretch}{1.3}
  \caption{Hyper-params selection - Sorted by lightest}
  \centering
  \label{tab:param-search2}
  \resizebox{\columnwidth}{!}{
  \begin{tabular}{ l l r r r r r}
      \hline\hline \\[-3mm]
      $ index $ & $L$x$N$ & \textbf{size} & $time(s)$ & $	\angle $ inclination & $avr \ MAE$\\
      \hline
      10        & 3x131   & \textbf{0.17} & 2112.38   & converges            & 2.5137   \\
       5        & 2x131   & \textbf{0.22} & 1429.48   & converges            & 3.0304   \\
       0        & 1x131   & \textbf{0.30} &  846.73   & converges            & 3.7015   \\
      11        & 3x262   & \textbf{0.64} & 2304.04   & converges            & 2.8515   \\
       6        & 2x262   & \textbf{0.85} & 1670.61   & converges            & 2.8789   \\
      \hline\hline
  \end{tabular}
  }
\end{table}

%
%
\subsection{Models results overview}
Implementation of several variations of time-series models allowed analysis of multiple paths of evolution of machine learning techniques in State of Charge estimation over the past three years.
A review of the resulting pros and cons, accuracies and complexity helps make a reasonable justification for further improvements.
Based on the summary of accuracies across entire training sets of all three profiles Table~\ref{tab:acc-results1}, the Highway way driving achieved the highest error, on validation and testing against either profile for all models.
Therefore, further observation will focus primaraly on DST and FUDS-based models and their efficiency at generalising other profiles.
The set of figure~\ref{} and early mentioned Table will act as 2 primaraly sources of the result for further overview and discussion.

%
%
Model \#1 has been based on the most simple and oldest research from 2017, made by Chemali \textit{et al.}~\cite{Chemali2017}.
Unlike during this research, back then, it utilised the simplest model structure with a single layer and no complicated cell modifications or optimiser enhancements.
% We used all temperatures ranges, where as he only 1-3. His method had 3.31 at out conditions, we lowered to 2.51
While he utilised from 1 to 3 temperature ranges, the modification of the hyperparameter increased the model's efficiency by 25\% at five different ambients, although not achieving as good results as theirs due to different methodologies and research goals.
% 2.77-ours, there his 0.77. He did Either C-D on one, or D on 3
However, with 2-3 times increased complexity of the input data, due to training on charge and discharge across five temperature ranges, the miss-accuracy only trippled, remaining below 5\% of an error.
Based on Table~\ref{tab:acc-results1}, it has the most stable accuracy across three different profiles compared to the others.
%!---It can be justified by the longest training time to reach the lowest error.
This model has shown good accuracies on US06 and FUDS datasets, but the training has not been very smooth, unlike with DST, as per Figure~\ref{fig:Model-1losses}.
By analysing Figure~\ref{fig:Model-1res}, the DST had the best results in capturing general behaviour on average.
However, the comparison Figure~\ref{fig:Model-1res} figures against tabled results create a false impression that FUDS makes a better training to capture other profiles in an isolated case, the table contridicts that in the overall FUDS doubles the error on other profiles, oppose to DST.
Subfigure~\ref{subfig:Model-1res-DSTvsFUDS} illustrates the area plot with the highest peaks compared to other plots.
It achieved the best capture of other profiles, but not the best at validation. Meaning that without reaching the lowest optimum error due to simplear optimiser, it did not lose the capture of either profiles for all 30 training cases.
%!---Contrary to DST, the US06 made the best result in capturing both features.
By analysing Table~\ref{tab:acc-results1}, US06 and FUDS results for Model \#1 can capture each other behaviour, but not the DST.


%
%
\textbf{Model 2 Placeholder. TO BE VEREFIED} \\ 
% Model \#2 was an attempt to move from an old LSTM to a recently developed GPU type of cell.
% Measuring the impact of such migration is not feasible.
% However, it utilised two different optimisers for the pre and fine-tuning phases.
% The transition happened after a third of the maximum allowed iterations, which in some cases led to high accuracy spikes in the training process, as seen in Figure~\ref{fig:Model-2losses}.
% The pre-tuning phase might have decreased the time to achieve the optimal results, but considering the number of input samples used - the difference is not noticeable between the LSTM and GPU models.
% Lowering the learning rate and switching the optimiser led to a much more stable learning curve but did not bring any improved prediction results.
% Despite that, training went smoother, except for minor anomalies on the FUDS training as per Model~\ref{fig:Model-2res}, the overall behaviour capture across profiles did not improve.
%\textcolor{red}{Matt: Do I even need to share my thoughts and refer to Table with potential why results worsened? I don't have an answer myself yet}

%
%
%! Model 3 repeats the same procedures as Model 1, except for an additional layer before the output.
Similar to the Model 1, Mamo utilised a single temperature rage, but with single or two profiles of DST, US06 or FUDS.
The use of only discharge cycle does not allows to make a comparison between results or *****.
%Adding the attention layer as per Model \# 3 did not make an overall improvement system improvement, but it produced much smoother outputs.
The prediction has a lesser variant and more smoother behaviour referring to a state of charge. 
The Absolute error fill showed none or less spike predictions on validation data.
%! Results on the DST model did now how any improvements as oppose to a simplear method.
%! However, a more complex profiles like US06 FUDS models and overall capture reasonable better. Validation illustrates the closer calture to the true SoC line  below 40\% of the charge at FUDS.
The less fluctuation model produces in the SoC prediction, the better its usability.
Model \#3 was able to achieve the lowest error twice faster but also went to overfit without learning step adjustment, as per Figure~\ref{fig:Model-3losses}.
It could make a reasonably good capture of all three profiles with US06 profiles.
Then as the FUDS model became much smoother in training with the attention layer, but still has difficulty in capturing 50\% charge in the testing scenarios on subfigure~\ref{subfig:Model-3res-FUDSvsUS}. 
%! Since the testing curve on the FUDS profile showed clear converges, unlike Model 1, the attention layer, along with improved optimiser, could have lead to even further improvement, as per Mamo work
%! Mamo used to combine the Attention layer with different optimiser, to work out multiple profile training.
%! However, the use of Differential Evolution was out of the scope of the research, focusing only on gradient optimisers.

%! Unlike a simpler model, the testing clearly shows the training line converges over time.
% improved on the FUDS training and better fir on Figure 9.i.
% Although it had a promising start by the training accuracy, the technique of adding more modified functional as a means to make the model better rather than just adding more layers to the model.
% Instable, variet, noisy

%
%
% Unlike other methods, Model \#4 utilised a stateful technique for the data input pipeline.
% Despite that, it has a promising approach but only in specific scenarios.
% For example, the training over DST has been conducted with both charge and discharge together, resetting the model at the end of the cycle, as per subfigure~\ref{subfig:Model-4res-DSTvsDST}.
% Having a charge in the system added complexity to the capture, but the error had a stable degradation over time as per Figure~\ref{fig:Model-4losses}.
% However, it had to be cut off early since the training threshold had not reached the set limit.
% It was attempted to be fixed on US06 and FUDS-based models, applying only to the discharge process.
% However, it did not bring much improvement and only made charge prediction more accurate than DST.
% For the general behaviour capture, stateful models are not suited by themself only.
% However, training two models separately for both charge and discharge or use it additional techniques on short prediction, for example, during acceleration events - the stateful model has usable applications.

%
%
%! According to all 3 profiles, an improved optimisers lead to a better capture on validation set, but further on the testing. Figures shows the improved capture at isolated case, but worse general capture as oppose to other models.
%! Unlike LSTM types. GRU went up to average 80 epochs, 
%! On Average, the GRU models achieved an optimum 3 times faster than LSTM. So, the prolong utilisation of the model is result of an optimiser. not a type of a cells
Similarly to the second method, Model \#5 applied a different optimiser.
However, additional complexity to other processing introduced better overall accuracy Table~\ref{tab:acc-results2}, as reported by Javid \textit{et al.}~\cite{javid_adaptive_2020}.
All three models experienced better training convergence in a shorter time, as per Figure~\ref{fig:Model-5losses}.
However, the difficulty in capturing the middle of a charge is still preserved.
%! Unlike other models, this one had a good recovery ability. In general, it took 2-5 attempts to return to original targeted minimum.
% Model 5: 1,3 model applied modification to the structure directly and fourth one indirectly. (2nd one did not, read again).
% There as (2?) and 5 improve optimisation steps, leading to better accuracy in all testing.
% RoAdam allowed faster convergences to the optimal accuracy and generaly achioeved better results by Table 2.

%
%
\textbf{Model 5 Placeholder. The importance of the optimiser, the simplest, does not mean the better or enginering efficient if it takes 100+ epochs to achieve results. In general, it has the least steepest learning curve in comparison to others} \\
% Model \#6 applied an additional LSTM layer with separated neurons to test better capturing.
% However, the result did not bring better error or faster convergence.
% In some cases, like wi\mbox{Two tables, \ref{tab:acc-results1} and \ref{tab:acc-results2}}, contains results of accuracy validation on six implemented models over entire drive cycles datasets.
% \mbox{Figures between \ref{fig:Model-1res} and \ref{fig:Model-6res}} demonstrated the best-selected cases for visual demonstration and comparison of training on one profile and validation against the other two.
% \mbox{Figures \ref{fig:Model-1losses} to \ref{fig:Model-6losses}} refer to the best model over the learning process, based on minimum Mean average or Root Mean Squared errors.

%
%
\subsection{Observations and discussions}
After analysing all six models, several comparisons can be derived from them.
Despite multiple tests over two cell types, there is no apparent advantage in using LSTM or GRU layers.
Two version of Model 1 with LSTM and GRU were tested to determine the impact of cell type.
Both models tended to achieve the same accuracy results.
GRU was able to achieve the optimim faster, after 7-10 epochs, with successes to recovery after 50 learning rate degradations.
%Models \#1 and \#2 give an illusion of an advantage to one model over another.
However, the accuracy plots in \mbox{Figures~\ref{fig:Model-1losses} and ~\ref{fig:Model-2losses}} indicate how error degrades with time for both models.
%One advantage over another is a simple matter of randomness in the initial training results.
\textbf{Capturing the middle area of charge, where voltage remains stable most of the time, is difficult, and DST may not be the best model for it.}

%
%
Model \#1 and \#6 have tested two approaches of neuron handling, either at single or dividing between multiple layers.
As a result, there was no significant advantage unless there were more modifications to the multilayer sequential model.
There as Model \#3 introduced additional custom computation without extra memory cells, leading to a smoother output.
The attention layer may not significantly boost the training or accuracy, but it gives a good foundation for further improvements and modifications.
Since the SoC estimation is not a pure number-based behaviour but also a matter of physical and electrical properties, manual adjustment weights, losses or data itself will not bring valuable results.
Further research and adjustments must be made using a similar principle to improve the training procedure with augmented models. 
For example, the sigmoid function selection in the model output minimises the possibility of going over 100\% or 0\% of charge.

%
%
Model \#2 and \#5 approach the convergence with optimisers modification.
The ensemble used two algorithms to speed up the long process of locating the local minimum and the second to tune up closer to it with an adjusted learning step.
However, the modified Adam version directly impacting the loss ratio improved the result drastically.
The advantage of modifying optimisers is better observed on the accuracy plots, \mbox{Figure~\ref{fig:Model-2losses} and ~\ref{fig:Model-5losses}}.
Model \#2 had better-avoided overfitting since it used two optimisers for quick adjustment and tuning.
Similar to Model \#5, which had a small learning rate, but modified parameter update with direct involvement of the loss values.
An early termination over \#5 and \#6 is a result of overfitting or apparent stability in the accuracy.
With the number of samples that the training process went through and based on the RMSE plot, there was little need for repeated training over the same data, as proven in the first several models.

\textbf{FUDS on Attention layers was able to capture more precise, as oppose to DST case. It's clearly visible on the Comparison to the Chemali2017 model and plots of the accuracies.}
%
%! [Refer to the bottom dicussion of stateful model]
% Model \#4 was the only one, which used a stateful model for training and testing.
% \textbf{Since every time-series model has a stateful internally, the difference is in the point of the model's reset.}
% It is more convenient for the State of Charge scenario to work with a short burst of data rather than attempt to preserve very long dependencies in a single run and be dependent to initial conditions.
% %
% %
% The best performance with Stateful models can be achieved through using a separate training process for charge and discharge. 
% \mbox{Subfigure~\ref{subfig:Model-4res-DSTvsDST}} demonstrates training over DST, which sufferers from high error in both charge and discharge process.
% The other two training were performed with discharge sets only, \mbox{Subfigures~\ref{subfig:Model-4res-UStr}, \ref{subfig:Model-4res-FUDStr}}.
% Stateful models can not be validated using traditional means of accurate measurement.
% \mbox{Table~\ref{tab:acc-results2}} for Model \#4 takes results from a single cycle only, same as~\ref{fig:Model-4res}, since there is no straightforward way to validate across all cycles (marked with $*$ symbol).

%
%
% Generally DST is bad for capturing as shown on all plots, which was expected initially. Although there was a chance that Dynamic stress test may act as a middle ground between Urban and highway driving.
% Acubs as comparison to model 1.
% However, the US06 acted as a better model, due to AAA!!!!
%
% Separating to multiple layers to the same amount of untis did not lead to improvements.
% It was the fastest what achieved the lowest training accuracy, but without affecting learning rate, model could not achieve capturing the other trens.
%
%
%
% This all shown that model not able to capture middle area.
% However, combining all 3 techniques into single model may lead to accurate results.
%
%
%
% Model 1,5,6 may be matter of randomness, more that just technique eficiency.
% DST generally faster singe profile itsekf is very easy to handle.
% + Model 4 had no means to perform test on entire set of both profiles.
%%%%%%%%%%%%%%%%%%%%
%% PUT both writing and the results from. After you do thatm compare the results as discussion. Expplicitly interpreter that.
%
%
% \subsection{******}
%
% 
%
%
Overall, there is an obvious advantage in training a model over a single profile and testing against similar scenarios, for example, creating a model that fits a single drive's driving behaviour over specific driving scenarios.
However, if models are placed under other conditions without a post-training process with new data, they will suffer from inaccuracies.
Comparison of the validation data act as a determining proof.
%
Continue of improvement on gradient optimiser appears to be a ded end. A RoAdam optimiser, or combination of two makes the best* results so far. However, the research did not provide any means or posibilities to build up optimisations even further.
The modification of the Cell type appears to be more promessing direction.