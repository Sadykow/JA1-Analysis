%? Person published this model ... [red]
%? Their accracy was ....
%? Our accuracy was .....
%? Reasons for differenct.
%?----
%? Reasons for difference in B
%? Why 1-4 better than 5
%? Why DST better
%? Wht #1 is best.
%! Which is best at reproducing itself? (4) Furthest fit
%! Which is best for real scenarios? 1 - Since it does not go too far into minimum, experiancing overfit with other models.
%! Which drive cycles is best to train? DST trained models

%
%
Model \#1 has been based on the most simple and oldest research, made by Chemali \textit{et al.}~\cite{Chemali2017} in 2017.
The original implementation utilised the simplest model structure with a single layer and no complicated cell modifications or optimiser enhancements.
% We used all temperature ranges, whereas he only 1-3. His method had 3.31 at out conditions; we lowered it to 2.51
While they utilised from 1 to 3 temperature ranges, the modification of the hyperparameter increased the model's efficiency by 25\% at five different ambients, although not achieving equally good results due to different methodologies and research goals.
% 2.77-ours, there his 0.77. He did Either C-D on one, or D on 3
However, with 2-3 times increased complexity of the input data, due to training on charge and discharge across five temperature ranges, the error only doubled, from Chemali \textit{et al.}~\cite{Chemali2017} 0.77-1.6\% to Models' 1.95-3.37\%.
% Based on Table~\ref{tab:acc-results1}, it has the most stable convergence across three different profiles compared to the other attempts.
%!---It can be justified by the longest training time to reach the lowest error.
% This model has not shown good accuracies on US06 and FUDS datasets, unlike with DST, due to the general simplicity of profiles' current behaviour.
%!---Contrary to DST, the US06 made the best result in capturing both features.
%!---By analysing Table~\ref{tab:acc-results1}, US06 and FUDS results for Model \#1 can capture each other behaviour, but not the DST.

%
%
Model \#2 was an attempt to move from an old LSTM to a recently developed GPU type of cell.
Both Adam and Nadam optimisers by themselves ran for half less epoch on GRU cell type than LSTM but achieved similar accuracies.
Embedding an additional optimiser with the same learning rate scheduling for pre and fine-tuning purposes doubled and tripled the training time.
%! General achieved above 99.2% of R2 on all experiments.
% However, it utilised two different optimisers for the pre and fine-tuning phases.
% The transition happened after a third of the maximum allowed iterations, which in some cases led to high accuracy spikes in the training process, as seen in Figure~\ref{fig:Model-2losses}.
% The pre-tuning phase might have decreased the time to achieve the optimal results, but considering the number of input samples used - the difference is not noticeable between the LSTM and GPU models.
While Xiao \textit{et al.}~\cite{xiao_accurate_2019} achieved above 99.2\% $R^2$ for all their cases, Model \#2 got by 1\% lover score, being trained on both charge and discharge.
However, based on individual temperature cases, an MAE for US06 was the lowest, in comparison to other profiles with 0.63\%, while based on Table~\ref{tab:acc-results1} FUDS achieved only 2.72\%
A significant difference is justified by the doubled amount of data and utilisation of variance of temperatures rather than exploring individual cases.
However, the history plots on Figure~\ref{fig:Model-2res} resemble the same pattern, indicating that the pre and fine-tune phases behaved similarly.
Lowering the learning rate and switching the optimiser led to a much more stable learning curve but did not bring any significantly improved prediction results.
% That effect can be observed on the DST and US06 validation plots, where the prediction line is far smoother compared to the other models.
% However, it did not bring any significant improvements to the overall performance.
% Despite that, training went smoother, except for minor anomalies on the FUDS training as per Model~\ref{fig:Model-2res}, the overall behaviour capture across profiles did not improve.
%\textcolor{red}{Matt: Do I even need to share my thoughts and refer to Table with potential why results worsened? I don't have an answer myself yet}

%
%
% %! Model 3 repeats the same procedures as Model 1, except for an additional layer before the output.
Similar to Model \#1, Mamo~\textit{et al.}~\cite{mamo_long_2020} utilised a single temperature rage but with single or two profiles of DST, US06 or FUDS.
Their use of only the discharge cycle does not allow direct comparison between results or plots.
%Adding the attention layer as per Model \# 3 did not make an overall improvement system improvement, but it produced much smoother outputs.
%* 0C : 0.2040\% 25C: 0.0757\%  45C: 0.11\%
However, their focus was on improving a simple LSTM to LSTM with attention, indicating an error reduction by 0.076-0.204\% for three temperature ranges.
%*3: US06: 5.97-5.38 FUDS: 5.03-4.02
%*3: US06: 5.98-5.27 FUDS: 5.33-3.61
Similar improvements can be observed between Model \#1 and \#3 on the testing data, except for DST, based on the overall performance, up to 0.4\% better fitting the other profiles, especially with US06.
%* 3: 2.60 - 4.14   1: 2.42 - 4.07
%*    3.00 - 4.32      2.96 - 3.94
%*    1.48 - 3.35      1.62 - 3.42
A similar pattern can be observed between Figures~\ref{fig:Model-3res} and ~\ref{fig:Model-1res} with 0.04\% and 0.14\% for US06 and FUDS, respectively.
% However, the prediction has a lesser variant and smoother behaviour referring to a state of charge. 
The Absolute error areal fill showed none or fewer spike predictions on validation data.
% Results on the DST model did not show noticeable improvements as opposed to the Model \#1, but still shows the lowest testing error against two other profiles.
%! However, more complex profiles like US06 FUDS models and overall capture are reasonable better.
% However, the general accuracy on more trendies profiles demonstrated a noticeable average improvement.
% Validation illustrates the closer capture of the SoC above 30\% of the charge at FUDS.
% The behaviour of the DST-based model is similar to Model \#1, with the same flaws in the charge and discharge curves.
%!---- Model \#3 was able to achieve the lowest error twice faster but also went to overfit without learning step adjustment, as per Figure~\ref{fig:Model-3losses}.
%! ----It could make a reasonably good capture of all three profiles with US06 profiles.
FUDS model became much smoother in training with the attention layer but still has difficulty in capturing above 40\% charge in the testing scenarios compared to the DST version, subfigure~\ref{subfig:Model-3res-testing}. 
% Unlike a simpler model, the testing clearly shows that the training line converges over time, which indicates an improvement toward generalising the more complex behaviours.
% improved on the FUDS training and better fir on Figure 9.i.
% Instable, variet, noisy
Besides the noticeable difference between the final results in comparison with Model \#3 and the equivalent published version, the efficiency of DST in capturing other profiles is the same.

%
%
%* Discharge only From simple to robust
%*  0C - 4.2 -> 1.08 = 3.12
%* 25C - 2.5 -> 1.1  = 1.4
%* 50C - 1.9 -> 0.84 = 1.06
Similarly to the second method, Model \#4 applied a different optimiser.
However, additional complexity to other processing introduced better overall accuracy Table~\ref{tab:acc-results1}, similar to what was reported by Javid~\textit{et al.}~\cite{javid_adaptive_2020}.
Based on their results, the error between a simple NN to Robust GRU lowered by 1.06-3.12\% for three individual temperature ranges.
A similar pattern can be observed between Model \#5 and \#4, where training error averages in the range of 1.89-2.94\%.
Just like it would between Javid~\textit{et al.}~\cite{javid_adaptive_2020} comparisons of NN with Unscented Kalman filter and Robust, and Model \#2 and \#4 in this work.
All three models experienced better training convergence in a shorter time, as per Figure~\ref{fig:Model-4res}.
% According to all three profiles, improved optimisers lead to better capture on the validation set but further on the testing.
Figures show the improved capture at the isolated case but worse general capture than other models.
% On Average, the GRU models achieve an optimum three times faster than LSTM.
% So, the prolonged utilisation of the model results from an optimiser, not a type of a cells
% However, the difficulty in capturing the below 30\% of a charge is still preserved.
% Unlike other models, this one had a good recovery ability with a learning rate lowering.
% Generally, it took 2-5 attempts to return to the initially targeted minimum.
%! Unlike Model 3, Model 4 failed to provide better cherectrisation to the area below 30 degrees, producing fluctiative reading.
% Model 5: 1,3 model applied modification to the structure directly and fourth one indirectly. (2nd one did not, read again).
% There as (2?) and 5 improve optimisation steps, leading to better accuracy in all testing.
%!---- RoAdam allowed faster convergences to the optimal accuracy and generaly achioeved better results by Table 2.

%
%
% \textcolor{red}{The importance of the simplest optimiser does not mean better or more engineering efficiency if it takes 100+ epochs to achieve results. In general, it has the least steep learning curve in comparison to others} \\
Model \#5 implemented the most straightforward case to compare the efficiency of standardly used Adam and robust variant optimisers% and outline the bottom line for optimisers.
Even though it is based on the work of Jiao~\textit{et al.}~\cite{jiao_gru-rnn_2020}, the purpose was to compare results and validate that Methodology can reach the limit of 100 epochs without breaking.
Their work has been performed on a battery tester at ambient temperature without reporting the batteries' internal, which leaves little possibility for error comparison.
Assuming a single temperature range within 25-30 degrees and discharge-only cycles, the accuracy error below 0.01\% and general $R^2$ above 99\% is tough to match.
However, it is an indication to explore the ML models' limitations and what areas of a State of Charge curve are harder to capture.
% Model \#5 is an indicator of the areas ML models have difficulties capturing.
Based on the SoC prediction absolute error area plots for DST and FUDS, Figure~\ref{fig:Model-5res}, the charge above 30\%, some degree between 90-80\% of discharge and below 50\% creates the highest discrepancies in the prediction.
Similar areas could have been observed on previously mentioned models with a lesser degree of miss accuracy.
Those behaviours outline the effect of temperatures on the SoCs curves, causing problems for models to characterise them all together.
% However, Model \#5 has proven to be the most effective in capturing US06 above all others.
Considering the general divergence of the testing curve and the MAE of the training trend approaching only an overall 1\% as opposed to other models, which a generally below that limit, it could be assumed that all attempts were less likely to overfit the given data.
%It produced the lowest accuracy for DST and FUDS, but managed to get the best fit for US06 and capture FUDS.
% \textcolor{red}{
% It is hard to justify, given that the average testing history curve only diverges with every epoch.
% Due to its' slow fitting process, assumingly, they reach only a single minimum.
% The models were focused on a single minimal without diving too deep into the optimal solutions.
% %Therefore capturing both high trendies cases.
% Despite that, considering the overall performance of the training process and results, it proves that Adam is a far superior optimisation strategy than its' predecessor SGD.
% }

%
%
Overall, the Attention layer of Model \#3 performed great at capturing complex behaviours like the FUDS profile.
In contrast, DST usage is suitable for describing other driving behaviours as a universal solution.
As per the research question of this work, DST-based Model \#1 acts as a superior model to all versions due to the lowest testing error, simplicity and lightweight.
However, the attention layer's impact on improving LSTM capturing characteristics is worth considering, apart from providing room for further improvements.
Yet, a combination of all four strategies used in every model may lead to far better outcomes in both complex capturing behaviour and generalising other driving profiles

%
%
% The initial methodology tested the impact of the neurons and layers on the model's accuracy to fit battery data.
% It tested an average of multiple sets and recorded several metrics to determine the best combination based on accuracy and size.
% Although the ultimate combination has not been achieved, it concluded that the higher numbers do not lead to better results.
% Doubling the number of neurons per layer may triple an occupied space without any accuracy or latency advantage.

%
%
% After analysing all five models, several comparisons can be derived from them.
% Despite multiple tests over two cell types, there is no apparent advantage in using LSTM or GRU layers.
% Two versions of Model \#1 with LSTM and GRU were tested to determine the impact of cell type.
% Both models tended to achieve the same accuracy but at different times.
% GRU generally achieves the optimum after 7-10 epochs, without the potential to recover, unlike LSTM. % after 50 learning rate degradations.
% The size of GRU was 30kB lower than LSTM, which is explained by a lower number of gates per neuron.
%Models \#1 and \#2 give an illusion of an advantage to one model over another.
%However, the accuracy plots in \mbox{Figures~\ref{fig:Model-1losses} and ~\ref{fig:Model-2losses}} indicate how error degrades with time for both models.

%

%
%
% Model \#5 \#1 and \#4 have tested the impact of the increased complexity of gradient-based optimiser.
% The first one demonstrated the speed at which a model achieves the optimum accuracy with minimal implementation.
% Since the Adam optimiser is inbuilt of SGD, it leads to an increased speed in the fitting process.
% The RoAdam introduced additional variables and equations to impact the learning process directly via loss value.
% It prolonged the training process without hitting an early overfit, improving the capture on the more complex profiles, like FUDS, giving no significant impact on DST. 
% \textbf{Therefore, it can be concluded that RoAdam optimiser is the best at capturing complex current behavior***}

%
%
% Model \#2 attempts to achieve the same thing as Model \#4 but focuses on already well-tested optimisers rather than modifying one of them. 
% The ensemble used two algorithms to speed up the long process of locating the local minimum and the second to tune up closer to it with an adjusted learning step.
% Model \#2 had better-avoided overfitting since it used two optimisers for quick adjustment and tuning.
% However, the original author's goal was to achieve the best minimum and tune the actual value as closely as possible.
% Unfortunately, the methodology attempted to exploit multiple minimal independently and take the average, breaking the original intention of producing a single good model, which will be based on a single profile only for training and testing.
% % Model \#2 and \#4 approach the convergence with optimisers modification.
% %
% The pre-tune phase of Model \#2 and results of Model \#1 indicates similarity in the error degradation, comparing Nadam and Adam optimisers.
% Their efficiency has been considered a trivial process to research since the difference is not as notable as between Adam and RoAdam.

%The advantage of modifying optimisers is better observed on the accuracy plots, \mbox{Figure~\ref{fig:Model-2losses} and ~\ref{fig:Model-5losses}}.
%However, the modified Adam version directly impacting the loss ratio improved the result drastically.
% Similar to Model \#4, which had a small learning rate, but modified parameter update with direct involvement of the loss values.
% An early termination over \#5 and \#6 is a result of overfitting or apparent stability in the accuracy.
%With the number of samples that the training process went through and based on the RMSE plot, there was little need for repeated training over the same data, as proven in the first several models.
%According to all thee profiles, an improved by a direct influence of loss function allows certain degree of adjustment, which is worth to consider.

%
%
% Models \#3 with the Attention layer captured complex profiles with higher accuracy like FUDS as opposed to DST, which is visible in comparison with Model \#1 plots.
% Since the testing curve on the FUDS profile showed clear converges, unlike Model \#1, the Attention layer, along with an improved optimiser, could have led to even further improvement, as per Mamo~\textit{et al.}~\cite{mamo_long_2020} work.
% Mamo combined the Attention layer with a statistical optimiser to work out multiple profile training and testing on a single.
% However, the use of Differential Evolution was out of the scope of the research, focusing only on gradient optimisers.
% Besides, the hyperparameters were fixed for all Models and predetermined beforehand, unlike in the original case.
% %* Size: 176328 bytes - Model 1
% %* Size: 187900 bytes - Model 3
% %* LEad to additional 11572 bytes in size after default compression.
% While changes in the neurons and layers lead to 50-500 KBs size increase, an Attention layer added only extra 11.5KBs of storage memory used after compression.
% % The attention layer may not significantly boost the training or accuracy, but it gives a good foundation for further improvements and modifications.
% Although it had a promising start by the training accuracy, the technique of adding more modified functions as a means to make the model better rather than just adding more layers or neurons to the model is a promising direction to explore.
% % There as Model \#3 introduced additional custom computation without extra memory cells, leading to a smoother output.


%
%! [Refer to the bottom dicussion of stateful model]
% Model \#4 was the only one, which used a stateful model for training and testing.
% \textbf{Since every time-series model has a stateful internally, the difference is in the point of the model's reset.}
% It is more convenient for the State of Charge scenario to work with a short burst of data rather than attempt to preserve very long dependencies in a single run and be dependent to initial conditions.
% %
% %
% The best performance with Stateful models can be achieved through using a separate training process for charge and discharge. 
% \mbox{Subfigure~\ref{subfig:Model-4res-DSTvsDST}} demonstrates training over DST, which sufferers from high error in both charge and discharge process.
% The other two training were performed with discharge sets only, \mbox{Subfigures~\ref{subfig:Model-4res-UStr}, \ref{subfig:Model-4res-FUDStr}}.
% Stateful models can not be validated using traditional means of accurate measurement.
% \mbox{Table~\ref{tab:acc-results2}} for Model \#4 takes results from a single cycle only, same as~\ref{fig:Model-4res}, since there is no straightforward way to validate across all cycles (marked with $*$ symbol).

%
%
% Acubs as a comparison to model 1.
% However, the US06 acted as a better model in ..., due to AAA!!!!
%
% Separating multiple layers to the same amount of units did not lead to improvements.
% It was the fastest what achieved the lowest training accuracy, but without affecting learning rate, model could not achieve capturing the other trens.
%
%
%
% This all shown that model not able to capture middle area.
% However, combining all 3 techniques into single model may lead to accurate results.
%
%
%
% Model 1,5,6 may be matter of randomness, more that just technique eficiency.
% DST generally faster singe profile itsekf is very easy to handle.
% + Model 4 had no means to perform test on entire set of both profiles.
%%%%%%%%%%%%%%%%%%%%
%% PUT both writing and the results from. After you do thatm compare the results as discussion. Expplicitly interpreter that.
%
%
% \subsection{******}
%
% 
%
%
% Voltage evolution during charge and discharge cycles is a primary source of characterising the behaviour of the State of Charge, as the current defines the direction and intensity.
% Therefore, distinguishing the flat region of the voltage of 3.3V (around 70-30\% of discharge) creates difficulties for an ML model in the least apparent current consumption cases, such as FUDS, due to Voltage Drops via Internal Resistance of a battery.
% The better models' capability to identify their trained profile, the worse they become in characterising the others.
% \textcolor{red}{
% That is why Model \#1 can be considered the best general use combination of cell type and optimiser since it does not go too far into achieving the lowest minimum, unlike Model \#5, and not experiencing overfit with other models.
% }
% % \textbf{Capturing the middle area of charge, where flat-region of the voltage remains stable most of the time, is difficult, and DST may not be the best for isolated case.}
% %
% \textcolor{red}{The comparison Figure~\ref{fig:Model-1res} against tabled results creates a false impression that FUDS does a better training to capture other profiles in an isolated case, the table contradicts that in the overall FUDSs doubles the error on other profiles, as opposed to DSTs.}
% ..OR..
% \textcolor{blue}{By analysing Figure~\ref{fig:Model-1res}, the DST had the best results in capturing the general behaviour of all three profiles due to its' simplicity and repentance in the current consumption, roughly 365 seconds per each subcycle, as opposed to 600 and 1400 for US06 and FUDS.}
% Subfigure~\ref{subfig:Model-1res-DSTvsFUDS} illustrates the area plot with the highest peaks compared to other figures.
% \textcolor{red}{It achieved the best capture of other profiles but not the best at validation.
% Meaning that without reaching the lowest optimum error due to a simpler optimiser, it did not lose the capture of either profile for all 30 training cases.}
% Generally, DST is bad for capturing, as shown on all plots across SoC prediction on validation.
% %Although there was a chance that the Dynamic stress test may act as a middle ground between Urban and highway driving.
% Although, that offset from the actual line during discharge, which can be observed across all models, makes a better characterisation of the SoC curve since the top and bottom percentage of the charge remains the same yet is capable of characterising all temperature ranges and profiles within 95-97\% accuracy.
% Such results make a DST pre-trained ML-based SoC model for deployment, which will later receive online training to fit the usability scenario, such as EVs.

%
%
% Since the SoC estimation is not a pure number-based behaviour but also a matter of physical and electrical properties, manual adjustment weights, losses or data itself will not bring valuable results.
% Further research and adjustments must be made using a similar principle to improve the training procedure with augmented models. 
% Such as the rollback feature, which has proven to be adequate to keep researched models within close range of epoch to calculate the average, as well as the training time reduction of all 285 models.
% \textbf{The techniques of determining optimal hyperparameters, efficient data selection and management, along with a promising direction toward further improvement, will assist in the development of a universal SoC estimation model in the future.}

%
%
% Overall, there is an obvious advantage in training a model over a single profile and testing against similar scenarios, for example, creating a model that fits a single drive's driving behaviour over specific driving scenarios.
% However, models placed under other conditions without a post-training process with new data will suffer from inaccuracies in the estimation.
% It is doubtful that one of those models will be efficient in a different condition or with another battery, despite its' age.
% Comparison of the validation and testing data act as determining proof.
% %
% Continued improvement on gradient optimiser appears to be a dead end.
% A RoAdam optimiser or combination of two makes the **best** results so far.
% However, the research did not provide any means or possibilities to build optimisations further.
% Therefore, modifying a cell type, models' structure, and training procedures appears to be a more promising direction.
