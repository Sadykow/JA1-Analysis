\BOOKMARK [1][-]{section.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.2}{Methodology}{}% 2
\BOOKMARK [2][-]{subsection.2.1}{Battery Data for training and validation}{section.2}% 3
\BOOKMARK [2][-]{subsection.2.2}{Dataset description and generator}{section.2}% 4
\BOOKMARK [2][-]{subsection.2.3}{Model training, validation and testing metrics functions}{section.2}% 5
\BOOKMARK [2][-]{subsection.2.4}{Hardware and Software}{section.2}% 6
\BOOKMARK [3][-]{subsubsection.2.4.1}{Embedded devices for performance measurements}{subsection.2.4}% 7
\BOOKMARK [3][-]{subsubsection.2.4.2}{Model training Framework}{subsection.2.4}% 8
\BOOKMARK [1][-]{section.3}{Machine Learning approach evaluated}{}% 9
\BOOKMARK [2][-]{subsection.3.1}{Model structure}{section.3}% 10
\BOOKMARK [3][-]{subsubsection.3.1.1}{Gated Recurrent Unit based models}{subsection.3.1}% 11
\BOOKMARK [3][-]{subsubsection.3.1.2}{Long-Short Term Memory based models}{subsection.3.1}% 12
\BOOKMARK [3][-]{subsubsection.3.1.3}{Attention Layer}{subsection.3.1}% 13
\BOOKMARK [2][-]{subsection.3.2}{Optimisers}{section.3}% 14
\BOOKMARK [3][-]{subsubsection.3.2.1}{Classic Stochastic Gradient and Momentum Stochastic Gradient algorithm}{subsection.3.2}% 15
\BOOKMARK [3][-]{subsubsection.3.2.2}{Adam and Robust Online Adam}{subsection.3.2}% 16
\BOOKMARK [3][-]{subsubsection.3.2.3}{Ensemble optimisation with Nadam and AdaMax}{subsection.3.2}% 17
\BOOKMARK [1][-]{section.4}{Performance and Results}{}% 18
\BOOKMARK [2][-]{subsection.4.1}{Accuracy overview}{section.4}% 19
\BOOKMARK [2][-]{subsection.4.2}{Hardware performcene overview}{section.4}% 20
\BOOKMARK [1][-]{section.5}{Conclusion}{}% 21
\BOOKMARK [1][-]{section.6}{Acknowledgements}{}% 22
\BOOKMARK [1][-]{section*.18}{References}{}% 23
